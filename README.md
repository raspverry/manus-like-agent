# Manus風AIエージェントシステム実装まとめ

## 実装した主要コンポーネント

1. **エージェントコア**
   - エージェントループロジック
   - コンテキスト管理
   - プランニングモジュール
   - メモリ管理

2. **ツール群**
   - メッセージツール：ユーザーとのコミュニケーション
   - ファイルツール：ファイルの読み書きや検索
   - シェルツール：コマンド実行
   - ブラウザツール：ウェブブラウジング（シミュレーション）
   - 情報ツール：ウェブ検索（シミュレーション）
   - デプロイツール：ポート公開やデプロイ（シミュレーション）

3. **設定とプロンプト**
   - システムプロンプト
   - 設定ファイル
   - README記述

## 主要な機能と設計ポイント

1. **CodeActパラダイム**：
   コードの実行によってアクションを表現する手法を採用しています。これにより、単純なツール呼び出しよりも柔軟性の高いアクションが可能になります。

2. **エージェントループ**：
   分析 → ツール選択 → 実行 → 観察 のループを繰り返すことで、複雑なタスクをステップバイステップで実行します。

3. **計画と分解**：
   複雑なタスクを小さなステップに分解し、todo.mdファイルで進捗を管理します。

4. **ファイルベースのメモリ**：
   重要な情報をファイルに保存することで、コンテキストウィンドウの制限を超えた情報の保持が可能になります。

5. **ツールの統合**：
   様々なツールを使ってエージェントの能力を拡張し、実世界でのアクションを可能にします。

## 使用開始方法

1. 必要なパッケージをインストール：
```bash
uv add -r requirements.txt
```

2. .envファイルにAPIキーを設定：
```
AZURE_OPENAI_API_KEY=your_azure_api_key

```

3. エージェントを起動：
```bash
uv run main.py
```

## 次のステップと拡張可能性

1. **実際のブラウザ統合**：
   PlaywrightやSeleniumを使った実際のブラウザ自動化を実装することで、ウェブサイトとの本格的な対話が可能になります。

2. **実際のデプロイ機能**：
   実際のクラウドサービス（Vercel、Netlify、AWSなど）との統合を実装することで、本物のデプロイ機能を追加できます。

3. **ベクトルデータベース統合**：
   ChromaやFAISSなどのベクトルデータベースを統合して、より高度な知識検索と記憶機能を実装できます。

4. **マルチモーダル対応**：
   画像、音声、その他のモダリティを処理するための追加ツールを実装することで、より広範なタスクに対応できます。

5. **マルチエージェント協調**：
   複数のエージェントが協力して作業できるシステムへと拡張することで、並列処理や専門化が可能になります。

6. **UI開発**：
   ウェブベースまたはデスクトップアプリケーション用のUIを開発して、ユーザービリティを向上させることができます。

7. **セキュリティ強化**：
   Dockerなどを使用した本格的なサンドボックス環境を実装することで、安全なコード実行が可能になります。

## コードカスタマイズのヒント

1. **新しいツールの追加**：
   `tools/` ディレクトリに新しいモジュールを作成し、`@tool` デコレータを使用して関数を定義します。`tool_registry.py` に登録するのを忘れないでください。

2. **プロンプトのカスタマイズ**：
   `prompts/system_prompt.txt` を編集して、エージェントの動作や役割を調整できます。

3. **LLMの変更**：
   OpenAIのGPT-4oを使用したい場合は、`config.py` の `llm.provider` を変更し、適切なAPIキーを設定します。

4. **制約とガードレールの調整**：
   `config.py` のセキュリティ設定やシステムプロンプト内のルールを調整して、エージェントの動作範囲を制御できます。

## 全体アーキテクチャとフロー
まず、main.py で CLI または Streamlit WebUI を起動し、そこからエージェント（Agent）を作成・実行しています。この構成は、以下のような “Manus風” のフローを実現している点で良いアプローチです:

1. ユーザーがタスクを入力する（CLI または UI）

2. そのタスクをエージェントへ渡す

3. エージェントが Planner でプランを作成

4. 作成したプランを イベントストリーム (Context) に登録

5. 繰り返し (ループ) で LLM に問い合わせ → LLMが「ツール呼び出し（関数）」をJSONで返す → 実行 → 観察結果をイベントとして再度 LLM に返す

6. 最終的に idle あるいはmax_iterations を超えたら終了


## 実際の動作も、おそらく下記のように流れるはずです:

1. ユーザーが Streamlit UI に「○○して」と入力

2. エージェントが “プラン” を生成し、イベントストリームに追加

3. LLM が「shell_exec」や「file_write」などの JSON を返す → 実行 → 結果を観察

4. 必要があればユーザーに message_ask_user でブロック質問

5. 最後に idle が返ったら終了
